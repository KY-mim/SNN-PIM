{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection Confusion Matrix - Optimization Ver.2\n",
    "* learn 함수 최적화\n",
    "    * 패턴 검색 방식 변경 : \n",
    "    for문 512번을 통해 검색하는 방식\n",
    "    -> 검색한 후, 검색된 횟수에 따라 learn을 진행하는 방식\n",
    "    * 정렬 방식 변경 : \n",
    "    learn마다 bubble sort 진행\n",
    "    -> 정렬 함수 생성 후, 추론 직전 최종 정렬 함수 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiMoPDL_GS2R"
   },
   "source": [
    "# 이미지 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CVf9zKC3IO4N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 17:13:15.401286: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/neurochip3/.pyenv/versions/3.9.8/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/neurochip3/.pyenv/versions/3.9.8/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/neurochip3/.pyenv/versions/3.9.8/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/neurochip3/.pyenv/versions/3.9.8/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time, inspect, os\n",
    "import knockknock\n",
    "from knockknock import telegram_sender\n",
    "\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlRSDXK9HgHR"
   },
   "source": [
    "## 이미지 download / resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLgC1V6FO6qx",
    "outputId": "67b9df57-98f0-42eb-a69b-7d3196ae11ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 17:13:18.304906: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-11-16 17:13:18.304933: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (clr-064ffa6064d8402181f1442d7a7d4225): /proc/driver/nvidia/version does not exist\n",
      "2022-11-16 17:13:18.305241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(train_images, train_labels),(test_images, test_labels)= keras.datasets.mnist.load_data() \n",
    "\n",
    "image_size = 28\n",
    "train_images = np.expand_dims(train_images, axis = -1)\n",
    "train_images = tf.image.resize(train_images,[image_size,image_size])\n",
    "train_images = np.squeeze(train_images)\n",
    "train_images= train_images/255.0\n",
    "\n",
    "test_images = np.expand_dims(test_images, axis = -1)\n",
    "test_images = tf.image.resize(test_images,[image_size,image_size])\n",
    "test_images = np.squeeze(test_images)\n",
    "test_images= test_images/255.0\n",
    "#이미지 resize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xeg_DWDHZuu"
   },
   "source": [
    "## 이미지 양자화\n",
    "0.3, 0.7 기준으로 (0 / 0.5 / 1)로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uEac2zWGH3Ax"
   },
   "outputs": [],
   "source": [
    "for k in range(train_images.shape[0]) :\n",
    "  for i in range(image_size):\n",
    "    for j in range(image_size):\n",
    "      if train_images[k, i,j] <0.3:\n",
    "        train_images[k, i, j] = 0\n",
    "      elif train_images[k, i,j] <0.7:\n",
    "        train_images[k, i,j] = 0.5\n",
    "      else :\n",
    "        train_images[k, i,j] = 1\n",
    "\n",
    "for k in range(test_images.shape[0]) :\n",
    "  for i in range(image_size):\n",
    "    for j in range(image_size):\n",
    "      if test_images[k, i,j] <0.3:\n",
    "        test_images[k, i, j] = 0\n",
    "      elif test_images[k, i,j] <0.7:\n",
    "        test_images[k, i,j] = 0.5\n",
    "      else :\n",
    "        test_images[k, i,j] = 1\n",
    "# 0 0.5 1 셋 중 하나의 값으로 바꿔줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQyY0P74HXRG"
   },
   "source": [
    "## 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "atfrIK-DH3a5"
   },
   "outputs": [],
   "source": [
    "###################데이터 나누기 \n",
    "train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "for k in range(train_images.shape[0]):\n",
    "  if train_labels[k] ==0:\n",
    "    train[0].append(train_images[k])\n",
    "  elif train_labels[k] ==1:\n",
    "    train[1].append(train_images[k])\n",
    "  elif train_labels[k] ==2:\n",
    "    train[2].append(train_images[k])\n",
    "  elif train_labels[k] ==3:\n",
    "    train[3].append(train_images[k])\n",
    "  elif train_labels[k] ==4:\n",
    "    train[4].append(train_images[k])\n",
    "  elif train_labels[k] ==5:\n",
    "    train[5].append(train_images[k])\n",
    "  elif train_labels[k] ==6:\n",
    "    train[6].append(train_images[k])\n",
    "  elif train_labels[k] ==7:\n",
    "    train[7].append(train_images[k])\n",
    "  elif train_labels[k] ==8:\n",
    "    train[8].append(train_images[k])\n",
    "  elif train_labels[k] ==9:\n",
    "    train[9].append(train_images[k])\n",
    "  else:\n",
    "    train_images[k] = train_images[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brm5FNmGF8jy"
   },
   "source": [
    "# Chip / Layer 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ro8huq7khcu7"
   },
   "source": [
    "## Chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "E7BXhuQRPCi5"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:86\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_address(self, pattern):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class chip:\n",
    "  def __init__(self, size, threshold1 = 0.9, threshold2 = 0.95):\n",
    "    '''\n",
    "    size = memory input size (input pattern size)\n",
    "    threshold1 = don't care  역치 //  0.9\n",
    "    threshold2 = 1 역치 // 0.95\n",
    "    '''\n",
    "    self.size = size\n",
    "    self.threshold1 = threshold1\n",
    "    self.threshold2 = threshold2\n",
    "    self.cam = []\n",
    "    self.counter = []\n",
    "    for i in range(2**size):\n",
    "      self.cam.append(i)\n",
    "      self.counter.append(0)\n",
    "\n",
    "  def reset(self):\n",
    "    '''\n",
    "    cam의 size를 입력받은 값으로 초기화\n",
    "    cam의 element를 0으로 초기화\n",
    "    '''\n",
    "    self.cam = []\n",
    "    self.counter = []\n",
    "    for i in range(2**self.size):\n",
    "      self.cam.append(i)\n",
    "      self.counter.append(0)\n",
    "\n",
    "  def pattern_to_number(self, pattern):\n",
    "    '''\n",
    "    입력받은 pattern을 number로 변환\n",
    "    (learn / get address 함수 내에서만 사용되므로 외부에서 사용할 필요 없음)\n",
    "    '''\n",
    "    num = 0\n",
    "    result = []\n",
    "    for i in range(len(pattern)):\n",
    "      if pattern[i] == 1:\n",
    "        num = num + 2**(len(pattern)-1-i)\n",
    "\n",
    "    result.append(num)\n",
    "    for i in range(len(pattern)):\n",
    "      if pattern[i]==0.5:\n",
    "        for k in range(len(result)):\n",
    "          result.append(result[k]+2**(len(pattern)-1-i))\n",
    "    \n",
    "    return result\n",
    "\n",
    "  def change_threshold(self, threshold1, threshold2):\n",
    "      self.threshold1 = threshold1\n",
    "      self.threshold2 = threshold2\n",
    "\n",
    "  def learn(self, pattern):\n",
    "    '''\n",
    "    입력받은 pattern(을 number로 변환한 값)이 cam[i]와 같으면(count!=0) counter 배열의 element를 1 더해주고,\n",
    "    counter 배열의 element에 따라 counter 배열과 cam 배열의 element를 동시에 정렬해 준다\n",
    "      (더 큰 count 횟수 -> 더 큰 index의 counter/cam 배열의 element)\n",
    "    '''\n",
    "    num = self.pattern_to_number(pattern)\n",
    "    self.counter[self.cam.index(num[0])] += 1\n",
    "    '''\n",
    "    ### 효율화 이전 ###\n",
    "    for i in range(len(self.cam)):\n",
    "      if num.count(self.cam[i])!=0:\n",
    "        self.counter[i] = self.counter[i] +1\n",
    "\n",
    "    for i in range(len(num)):\n",
    "      for j in range(len(self.cam)-1):\n",
    "        if self.counter[j] > self.counter[j+1]:\n",
    "          temp =self.counter[j]\n",
    "          self.counter[j] = self.counter[j+1]\n",
    "          self.counter[j+1] = temp\n",
    "          temp =self.cam[j]\n",
    "          self.cam[j] = self.cam[j+1]\n",
    "          self.cam[j+1] = temp\n",
    "    '''\n",
    "  def sort(self):\n",
    "      d = dict()\n",
    "      for i in range(len(self.counter)):\n",
    "          d[cam[i]] = counter[i]\n",
    "      d = sorted(d.items(), key = lambda item: item[1])\n",
    "      self.counter = []\n",
    "      self.cam = []\n",
    "      for i in range(len(d)):\n",
    "          self.counter.append(d[i][1])\n",
    "          self.cam.append(d[i][0])\n",
    "          \n",
    "    def get_address(self, pattern):\n",
    "    '''\n",
    "    입력받은 pattern에 대한 address(cam?의 index)를 반환\n",
    "    '''\n",
    "    num = self.pattern_to_number(pattern)\n",
    "    result = []\n",
    "    for i in range(len(num)):\n",
    "      result.append(self.cam.index(num[i]))\n",
    "    return result\n",
    "  \n",
    "  def get_binary(self, pattern):\n",
    "    '''\n",
    "    입력받은 pattern에 대한 출력값(0, 0.5, 1)을 반환\n",
    "      (get_address의 result가\n",
    "      하단 임계점을 넘으면 0.5, 상단 임계점을 넘으면 1 반환)\n",
    "    '''\n",
    "    result = self.get_address(pattern)\n",
    "    address = max(result)\n",
    "    percent = address/len(self.cam)\n",
    "\n",
    "    if percent < self.threshold1 :\n",
    "      return 0.0\n",
    "    elif percent <self.threshold2:\n",
    "      return 0.5\n",
    "    else:\n",
    "      return 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tx4M5Ws9hjWC"
   },
   "source": [
    "## Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gS_8SxOhlcC"
   },
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, window_size, layer_size, stride = 0, threshold1 = 0.9, threshold2 = 0.95):\n",
    "        self.L = [[0]*layer_size for _ in range(layer_size)]\n",
    "        self.threshold1 = threshold1\n",
    "        self.threshold2 = threshold2\n",
    "        for i in range(layer_size):\n",
    "            for j in range(layer_size):\n",
    "                self.L[i][j] = chip(window_size*window_size, self.threshold1, self.threshold2)\n",
    "        \n",
    "        if stride ==0:\n",
    "            self.stride = window_size\n",
    "        else :\n",
    "            self.stride = stride\n",
    "        self.window_size = window_size\n",
    "        self.layer_size = layer_size\n",
    "\n",
    "    def reset(self):\n",
    "        '''\n",
    "        layer가 초기화\n",
    "        내부 chip의 배열도 초기화\n",
    "        '''\n",
    "        for i in range(self.layer_size):\n",
    "            for j in range(self.layer_size):\n",
    "                self.L[i][j].reset()\n",
    "\n",
    "    def change_threshold(self, threshold1, threshold2):\n",
    "        self.threshold1 = threshold1\n",
    "        self.threshold2 = threshold2\n",
    "        for i in range(self.layer_size):\n",
    "            for j in range(self.layer_size):\n",
    "                self.L[i][j].change_threshold(threshold1, threshold2)\n",
    "\n",
    "    def learn(self, image):\n",
    "        '''\n",
    "        이미지 하나를 layer가 입력받게 되는 함수\n",
    "        이미지 크기 : i * j\n",
    "        window(pattern) 크기 : a * b\n",
    "        '''\n",
    "        # 학습 가능한 이미지 사이즈인지 확인하는 코드 추가 작성\n",
    "        for i in range(self.layer_size):\n",
    "            for j in range(self.layer_size):\n",
    "                pattern= []\n",
    "                for a in range(self.window_size):\n",
    "                    for b in range(self.window_size):\n",
    "                        pattern.append(image[self.stride*i+a][self.stride*j+b])\n",
    "                self.L[i][j].learn(pattern)\n",
    "    \n",
    "    def sort(self):\n",
    "        for i in range(self.layer_size):\n",
    "            for j in range(self.layer_size):\n",
    "                self.L[i][j].sort()\n",
    "    \n",
    "    def out(self, image):\n",
    "        '''\n",
    "        이미지 넣고 출력되는 layer out 보여줌\n",
    "        '''\n",
    "        # 입력 가능한 이미지 사이즈인지 확인하는 코드 추가 작성\n",
    "        out_image = [[0] * self.layer_size for _ in range(self.layer_size)]\n",
    "        for i in range(self.layer_size):\n",
    "            for j in range(self.layer_size):\n",
    "                pattern=[]\n",
    "                for a in range(self.window_size):\n",
    "                    for b in range(self.window_size):\n",
    "                        pattern.append(image[self.stride*i +a][self.stride*j +b])\n",
    "                out_image[i][j] = self.L[i][j].get_binary(pattern)\n",
    "        return out_image\n",
    "\n",
    "    def out_address(self,image):\n",
    "        '''\n",
    "        마지막 레이어의 주소를 반환\n",
    "        '''\n",
    "        out_image = [[0] * self.layer_size for _ in range(self.layer_size)]\n",
    "        for i in range(self.layer_size):\n",
    "            for j in range(self.layer_size):\n",
    "                pattern=[]\n",
    "                for a in range(self.window_size):\n",
    "                    for b in range(self.window_size):\n",
    "                        pattern.append(image[self.stride*i +a][self.stride*j +b])\n",
    "                out_image[i][j] = max(self.L[i][j].get_address(pattern))\n",
    "        return out_image   \n",
    "\n",
    "    def out_size(self):\n",
    "        '''\n",
    "        N*N 출력 이미지에서 N(size)이 나옴 \n",
    "        '''\n",
    "        return self.layer_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnwzapUJhrZz"
   },
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzhfTrwvXrcR"
   },
   "source": [
    "## 6 - Filtering CAM(`Chip`) 학습\n",
    "size 4의 Chip을 선언하고 수평, 수직, 반대각, 주대각을 학습하는 데이터를 학습한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbXCohOh29vG"
   },
   "outputs": [],
   "source": [
    "edge_detection = chip(4,threshold1 = 14/16, threshold2=14/16)\n",
    "\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def filtering_cam_learning():\n",
    "    #수평 = H\n",
    "    for i in range (8):\n",
    "        edge_detection.learn([1,1,0,0])\n",
    "        edge_detection.learn([0,0,1,1])\n",
    "    #수직 = V\n",
    "    for i in range (6):\n",
    "        edge_detection.learn([1,0,1,0])\n",
    "        edge_detection.learn([0,1,0,1])\n",
    "    #반대각(ㅢ) = R\n",
    "    for i in range (4):\n",
    "        edge_detection.learn([1,0,0,0])\n",
    "        edge_detection.learn([0,1,1,1])\n",
    "    #주대각(ㄴ) = L\n",
    "    for i in range (2):\n",
    "        edge_detection.learn([0,1,0,0])\n",
    "        edge_detection.learn([1,0,1,1])\n",
    "\n",
    "filtering_cam_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVDxGrdaQyyf"
   },
   "source": [
    "## 7 - Edge Detection : `Chip` 배열\n",
    "H, V, R, L의 배열(0 - 9)을 선언하고 각 배열의 element를 27*27로 만들어 준다.\n",
    "\n",
    "전처리한 image(`data`)를 입력해 수평/수직/반대각/주대각(H, V, R, L)의 배열에 해당 패턴이 발견되면 1, 발견되지 않으면 0으로 입력한다.\n",
    "\n",
    "`k`는 0 - 9\n",
    "\n",
    "`a`는 각 숫자의 mnist 이미지\n",
    "\n",
    "`i`, `j`는 이미지의 위치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8g8fgAi19uh2"
   },
   "outputs": [],
   "source": [
    "H = [[],[],[],[],[],[],[],[],[],[]]\n",
    "V = [[],[],[],[],[],[],[],[],[],[]]\n",
    "R = [[],[],[],[],[],[],[],[],[],[]]\n",
    "L = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_edge_detection():\n",
    "    for k in range(10):\n",
    "        for a in range(len(train[k])) :\n",
    "            data = train[k][a]    \n",
    "            H[k].append([[0] * 27 for _ in range(27)])\n",
    "            V[k].append([[0] * 27 for _ in range(27)])\n",
    "            R[k].append([[0] * 27 for _ in range(27)])\n",
    "            L[k].append([[0] * 27 for _ in range(27)])\n",
    "            for i in range(27):\n",
    "                for j in range(27):\n",
    "                    address = []\n",
    "                    pattern = []\n",
    "                    pattern = [(data[i][j]),(data[i][j+1]),\n",
    "                            (data[i+1][j]),(data[i+1][j+1])]\n",
    "                    address = edge_detection.get_address(pattern)\n",
    "                    if 15 in address:\n",
    "                        H[k][a][i][j] = 1\n",
    "                    elif 14 in address:\n",
    "                        H[k][a][i][j] = 1\n",
    "                    else : H[k][a][i][j] = 0\n",
    "\n",
    "                    if 13 in address:\n",
    "                        V[k][a][i][j] = 1\n",
    "                    elif 12 in address:\n",
    "                        V[k][a][i][j] = 1\n",
    "                    else : V[k][a][i][j] = 0\n",
    "\n",
    "                    if 11 in address:\n",
    "                        R[k][a][i][j] = 1\n",
    "                    elif 10 in address:\n",
    "                        R[k][a][i][j] = 1\n",
    "                    else : R[k][a][i][j] = 0\n",
    "\n",
    "                    if 9 in address:\n",
    "                        L[k][a][i][j] = 1\n",
    "                    elif 8 in address:\n",
    "                        L[k][a][i][j] = 1\n",
    "                    else : L[k][a][i][j] = 0\n",
    "\n",
    "modellearning_edge_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer_H1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_H():\n",
    "    for k in range(10):\n",
    "        Layer_H1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in H[k]:\n",
    "            Layer_H1[k].learn(data)\n",
    "Layer_V1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_V():\n",
    "    for k in range(10):\n",
    "        Layer_V1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in V[k]:\n",
    "            Layer_V1[k].learn(data)\n",
    "Layer_R1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_R():\n",
    "    for k in range(10):\n",
    "        Layer_R1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in R[k]:\n",
    "            Layer_R1[k].learn(data)\n",
    "\n",
    "Layer_L1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_L():\n",
    "    for k in range(10):\n",
    "        Layer_L1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in L[k]:\n",
    "            Layer_L1[k].learn(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer_H1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def multi_modellearning_layer_H():\n",
    "    for k in range(10):\n",
    "        Layer_H1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in H[k]:\n",
    "            Layer_H1[k].learn(data)\n",
    "Layer_V1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def multi_modellearning_layer_V():\n",
    "    for k in range(10):\n",
    "        Layer_V1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in V[k]:\n",
    "            Layer_V1[k].learn(data)\n",
    "Layer_R1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def multi_modellearning_layer_R():\n",
    "    for k in range(10):\n",
    "        Layer_R1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in R[k]:\n",
    "            Layer_R1[k].learn(data)\n",
    "\n",
    "Layer_L1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def multi_modellearning_layer_L():\n",
    "    for k in range(10):\n",
    "        Layer_L1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in L[k]:\n",
    "            Layer_L1[k].learn(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def now_not_multi_threding():\n",
    "    multithreding = \"not_multi-thrhreding\"\n",
    "    return multithreding\n",
    "now_not_multi_threding()\n",
    "\n",
    "Layer_H1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_H()\n",
    "Layer_V1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_V()\n",
    "Layer_R1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_R()\n",
    "Layer_L1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_L()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def now_multi_PROCESSING():\n",
    "    multi = \"multi-PROCESSING\"\n",
    "    return multi\n",
    "now_multi_PROCESSING()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "p1 = multiprocessing.Process(name = \"subprocess1\", target=multi_modellearning_layer_H)\n",
    "p2 = multiprocessing.Process(name = \"subprocess2\", target=multi_modellearning_layer_V)\n",
    "p3 = multiprocessing.Process(name = \"subprocess3\", target=multi_modellearning_layer_R)\n",
    "p4 = multiprocessing.Process(name = \"subprocess4\", target=multi_modellearning_layer_L)\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "p4.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.join()\n",
    "p2.join()\n",
    "p3.join()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def now_multi_threding():\n",
    "    multithreding = \"multi-thrhreding\"\n",
    "    return multithreding\n",
    "now_multi_threding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "Layer_H1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "Layer_V1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "Layer_R1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "Layer_L1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "t1 = threading.Thread(target=multi_modellearning_layer_H)\n",
    "t2 = threading.Thread(target=multi_modellearning_layer_V)\n",
    "t3 = threading.Thread(target=multi_modellearning_layer_R)\n",
    "t4 = threading.Thread(target=multi_modellearning_layer_L)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def now_not_multi_threding():\n",
    "    multithreding = \"not_multi-thrhreding\"\n",
    "    return multithreding\n",
    "now_not_multi_threding().py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layer_H1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_H()\n",
    "Layer_V1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_V()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLUAyGuuRouP"
   },
   "source": [
    "# Memory Learning **⟵ 여기부터**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ko0cfseXVu2"
   },
   "source": [
    "## 8 - Layer 학습\n",
    "\n",
    "Edge detection을 완료한 image(`data in H[k] - L[k]`)를 Layer_H1[0] - Layer_H1[9], Layer_V1[0 - 9], Layer_R1[0 - 9], Layer_L1[0 - 9]에 대해 학습(`learn`)\n",
    "\n",
    "`window size`=3\n",
    "`layer size`=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반 함수\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_H():\n",
    "    for k in range(10):\n",
    "        Layer_H1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in H[k]:\n",
    "            Layer_H1[k].learn(data)\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_V():\n",
    "    for k in range(10):\n",
    "        Layer_V1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in V[k]:\n",
    "            Layer_V1[k].learn(data)\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_R():\n",
    "    for k in range(10):\n",
    "        Layer_R1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in R[k]:\n",
    "            Layer_R1[k].learn(data)\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_L():\n",
    "    for k in range(10):\n",
    "        Layer_L1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in L[k]:\n",
    "            Layer_L1[k].learn(data)\n",
    "\n",
    "# multi 함수\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def optimizated_modellearning_layer_H():\n",
    "    for k in range(10):\n",
    "        Layer_H1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in H[k]:\n",
    "            Layer_H1[k].learn(data)\n",
    "    for k in range(10):\n",
    "        Layer_H1[k].sort()\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def optimizated_modellearning_layer_V():\n",
    "    for k in range(10):\n",
    "        Layer_V1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in V[k]:\n",
    "            Layer_V1[k].learn(data)\n",
    "    for k in range(10):\n",
    "        Layer_V1[k].sort()\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def optimizated_modellearning_layer_R():\n",
    "    for k in range(10):\n",
    "        Layer_R1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in R[k]:\n",
    "            Layer_R1[k].learn(data)\n",
    "    for k in range(10):\n",
    "        Layer_R1[k].sort()\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def optimizated_modellearning_layer_L():\n",
    "    for k in range(10):\n",
    "        Layer_L1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in L[k]:\n",
    "            Layer_L1[k].learn(data)\n",
    "    for k in range(10):\n",
    "        Layer_L1[k].sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not - multi - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def now_not_multi_threding():\n",
    "    multithreding = \"not_multi-thrhreding\"\n",
    "    return multithreding\n",
    "now_not_multi_threding()\n",
    "\n",
    "Layer_H1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_H()\n",
    "Layer_V1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_V()\n",
    "Layer_R1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_R()\n",
    "Layer_L1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "modellearning_layer_L()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi - processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def now_multi_PROCESSING():\n",
    "    multi = \"multi-PROCESSING\"\n",
    "    return multi\n",
    "now_multi_PROCESSING()\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "p1 = multiprocessing.Process(name = \"subprocess1\", target=multi_modellearning_layer_H)\n",
    "p2 = multiprocessing.Process(name = \"subprocess2\", target=multi_modellearning_layer_V)\n",
    "p3 = multiprocessing.Process(name = \"subprocess3\", target=multi_modellearning_layer_R)\n",
    "p4 = multiprocessing.Process(name = \"subprocess4\", target=multi_modellearning_layer_L)\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p3.start()\n",
    "p4.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.join()\n",
    "p4.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi - threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def now_multi_threding():\n",
    "    multithreding = \"multi-thrhreding\"\n",
    "    return multithreding\n",
    "now_multi_threding()\n",
    "\n",
    "import threading\n",
    "import time\n",
    "Layer_H1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "Layer_V1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "Layer_R1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "Layer_L1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "t1 = threading.Thread(target=multi_modellearning_layer_H)\n",
    "t2 = threading.Thread(target=multi_modellearning_layer_V)\n",
    "t3 = threading.Thread(target=multi_modellearning_layer_R)\n",
    "t4 = threading.Thread(target=multi_modellearning_layer_L)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "t4.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존 방식(백업용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mas5Tm3nPKsn"
   },
   "outputs": [],
   "source": [
    "Layer_H1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_H():\n",
    "    for k in range(10):\n",
    "        Layer_H1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in H[k]:\n",
    "            Layer_H1[k].learn(data)\n",
    "modellearning_layer_H()        \n",
    "\n",
    "Layer_V1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_V():\n",
    "    for k in range(10):\n",
    "        Layer_V1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in V[k]:\n",
    "            Layer_V1[k].learn(data)\n",
    "modellearning_layer_V()\n",
    "\n",
    "Layer_R1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_R():\n",
    "    for k in range(10):\n",
    "        Layer_R1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in R[k]:\n",
    "            Layer_R1[k].learn(data)\n",
    "modellearning_layer_R()\n",
    "\n",
    "Layer_L1 = [0,0,0,0,0,0,0,0,0,0]\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modellearning_layer_L():\n",
    "    for k in range(10):\n",
    "        Layer_L1[k] = layer(3,9, stride= 0, threshold1 = 0.90, threshold2 = 0.96)\n",
    "        for data in L[k]:\n",
    "            Layer_L1[k].learn(data)\n",
    "modellearning_layer_L()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvf5CwTJbFYo"
   },
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EhkKV3X95yJ"
   },
   "source": [
    "## 9 - Validation data Edge detection / Searching\n",
    "위의 H, V, R, L과 동일한 방식으로 H_temp, V_temp, R_temp, L_temp 학습\n",
    "\n",
    "i = 0부터 9까지 10번 반복, Layer_H1[0] - Layer_H1[9], Layer_V1[0 - 9], Layer_R1[0 - 9], Layer_L1[0 - 9]에 대해 반복 수행\n",
    "\n",
    "H,V,R,L 중 가장 큰 값을 도출하는(maximum of (`H[0] + V[0] + R[0] + L[0]` - `H[9] + V[9] + R[9] + L[9]`)) 값을 `answer`로 출력.\n",
    "\n",
    "정답과 같으면 `right = right + 1`, 틀리면 `wrong = wrong + 1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjaWehqk_pf7"
   },
   "outputs": [],
   "source": [
    "right = 0\n",
    "wrong = 0\n",
    "H_temp = [[0] * 27 for _ in range(27)]\n",
    "V_temp = [[0] * 27 for _ in range(27)]\n",
    "R_temp = [[0] * 27 for _ in range(27)]\n",
    "L_temp = [[0] * 27 for _ in range(27)]\n",
    "confusion = [[0] * 10 for _ in range(10)]\n",
    "\n",
    "for k in range(len(test_images)):\n",
    "    data = test_images[k]\n",
    "    out_address = []\n",
    "    out_result=[]\n",
    "\n",
    "    for i in range(27):\n",
    "        for j in range(27):\n",
    "            pattern = []\n",
    "            pattern = [(data[i][j]),(data[i][j+1]),\n",
    "                      (data[i+1][j]),(data[i+1][j+1])]\n",
    "            address = edge_detection.get_address(pattern)\n",
    "            if 15 in address:\n",
    "                H_temp[i][j] = 1\n",
    "            elif 14 in address:\n",
    "                H_temp[i][j] = 1\n",
    "            else : H_temp[i][j] = 0\n",
    "\n",
    "            if 13 in address:\n",
    "                V_temp[i][j] = 1\n",
    "            elif 12 in address:\n",
    "                V_temp[i][j] = 1\n",
    "            else : V_temp[i][j] = 0\n",
    "\n",
    "            if 11 in address:\n",
    "                R_temp[i][j] = 1\n",
    "            elif 10 in address:\n",
    "                R_temp[i][j] = 1\n",
    "            else : R_temp[i][j] = 0\n",
    "            \n",
    "            if 9 in address:\n",
    "                L_temp[i][j] = 1\n",
    "            elif 8 in address:\n",
    "                L_temp[i][j] = 1\n",
    "            else : L_temp[i][j] = 0\n",
    "\n",
    "#여기까지 H_temp, V_temp, R_temp, L_temp 초기화\n",
    "#여기부터 i = 0부터 9까지 10번 반복, Layer_H1[0]부터 Layer_H1[9]까지, V, R, L까지 반복 수행\n",
    "\n",
    "    for i in range(10):\n",
    "        out_H = Layer_H1[i].out(H_temp)\n",
    "        out_V = Layer_V1[i].out(V_temp)\n",
    "        out_R = Layer_R1[i].out(R_temp)\n",
    "        out_L = Layer_L1[i].out(L_temp)\n",
    "\n",
    "        out_H_ = sum(out_H,[])\n",
    "        out_V_ = sum(out_V,[])\n",
    "        out_R_ = sum(out_R,[])\n",
    "        out_L_ = sum(out_L,[])\n",
    "\n",
    "        out = sum(out_H_)+sum(out_V_)+sum(out_R_)+sum(out_L_)\n",
    "        out_result.append(out)\n",
    "        \n",
    "    answer = out_result.index(max(out_result))\n",
    "\n",
    "    confusion[test_labels[k]][answer] = confusion[answer][test_labels[k]] + 1\n",
    "    if answer == test_labels[k]:\n",
    "        right = right +1\n",
    "    else :\n",
    "        wrong = wrong + 1\n",
    "print(right / (right + wrong))\n",
    "\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modelvalidation(input):\n",
    "  print(input)\n",
    "  return input\n",
    "modelvalidation(right / (right + wrong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqAaTUAXbmKl"
   },
   "source": [
    "## 결과 시각화(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChgYfcOzRxLo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "conf = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "for i in range(10):\n",
    "    conf[i] = 100/sum(confusion[i])\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        confusion[i][j] = confusion[i][j]*conf[i]\n",
    "    \n",
    "df = pd.DataFrame(data = {'label_0' : confusion[0],\n",
    "                          'label_1' : confusion[1],\n",
    "                          'label_2' : confusion[2],\n",
    "                          'label_3' : confusion[3], \n",
    "                          'label_4' : confusion[4],\n",
    "                          'label_5' : confusion[5],\n",
    "                          'label_6' : confusion[6],\n",
    "                          'label_7' : confusion[7],\n",
    "                          'label_8' : confusion[8],\n",
    "                          'label_9' : confusion[9]\n",
    "                         }\n",
    "                 ,index = ['0','1','2','3','4','5','6','7','8','9']\n",
    "                 )\n",
    "\n",
    "df\n",
    "@telegram_sender(token=\"5594017285:AAGaj_6-ZIx-QKXVixZb35X_ACcCVQr6w-U\", chat_id=16579436)\n",
    "def modelvalidation_calc_accuracy():\n",
    "  overall_accuracy = ((confusion[0][0] + confusion[1][1] + confusion[2][2] + confusion[3][3] + confusion[4][4] + confusion[5][5] + confusion[6][6] + confusion[7][7] + confusion[8][8] + confusion[9][9]) / 10)\n",
    "  #print((confusion[0][0] + confusion[1][1] + confusion[2][2] + confusion[3][3] + confusion[4][4] + confusion[5][5] + confusion[6][6] + confusion[7][7] + confusion[8][8] + confusion[9][9]))\n",
    "  print(overall_accuracy)\n",
    "  return overall_accuracy\n",
    "modelvalidation_calc_accuracy()\n",
    "\n",
    "currentfilename = inspect.getfile(inspect.currentframe()) #현재 파일이 >위치한 경로 + 현재 파일명\n",
    "currentfilename = (currentfilename.split(\"\\\\\")[-1]).split('.')[0] #현재 파일명만 추출\n",
    "print(currentfilename, \" : COMPLETED\") #현재 파일명 : COMPLETED 출력\n",
    "filename = time.strftime(\"result/%y%m%d_%H%M%S[\" + currentfilename + \"].txt\", time.localtime(time.time())) #결과 파일명 정의\n",
    "outputfile = open(filename, 'w') #결과 파일 생성\n",
    "outputfile.write('COMPLETED AT : ' + time.strftime('%y-%m-%d %a_%H:%M:%S', time.localtime(time.time()))) #파일 : 완료된 시각\n",
    "outputfile.write('\\n' + \"   RESULT OF : \" + currentfilename + '\\n') #파일 : 완료된 파일명\n",
    "outputfile.write('\\n' + df + '\\n') #파일 : 완료된 파일명\n",
    "outputfile.close #파일 편집 종료outputfile = open(filename, 'a') #결과 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwvJ4E8_dxi_"
   },
   "outputs": [],
   "source": [
    "#confusion.size()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q03zys9azdzb"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for j in range(9):\n",
    "        for k in range(9):\n",
    "            if(Layer_H1[i].L[j][k].counter[384] != 0) :\n",
    "                print(\"i: \", i, \"j: \", j, \"k: \", k)\n",
    "                print(Layer_H1[i].L[j][k].cam)\n",
    "                print(Layer_H1[i].L[j][k].counter) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "edge_detection_confusion_matrix (3).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit ('3.9.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "3145ad7ebda48d6e98803c948c09cf837e404bfad2388f8fc8083a1f7c4e6d81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
